# Movie Recommendation Engine:

A Recommender system is a simple algorithm, whose aim is to provide the most relevant information to a user by discovering patterns in a dataset. In this project, we have followed Collaborative Filtering technique to build the Movie Recommendation Engine. 

In the collaborative filtering method, recommendations for each user are generated by making comparisons with the liking for one alternative over another of other users who have qualified the product similar to the active user. Collaborative filtering is based on the idea that people who agree with the evaluation of items in the past are likely to agree again in the future.



# Dataset:
1M Dataset was obtained from `MovieLens database` (https://grouplens.org/datasets/movielens/1m/). The input data set will consist of four columns namely user_id, movie_id, ratings, and timestamp.



# Data cleaning and Preprocessing:

Before training the dataset, we analysed the dataset and removed the outliers. 

Visulaized the dataset by plotting graphs and understand the trends between Movie_ids and User_ids using `Matplotlib` and `Searborn` modules.

Encoded the DataFrame by assigning continuous values in each rows, so that it'll be easy to train. 



# Training the dataset:

Created a Sparse matrix called `Actual Matrix` using `csc_matrix` method imported from `scipy.sparse` library. 
The Actual Matrix is the sum of product of the columns - Movie_id and User_id. 

Created `Embeddings`, for columns- movie_id and user_id, and converted to Embedding array/matrix using `Numpy` module. 
  
    Embedding matrix is giving a specific value to each word/id such that it contains a array of embedded integers.
   
Mathematical operations like multiplication and additions were performed using `Numpy` module on the embedded values, to get the `Predicted` value column for the the dataframe.

Another, Sparse Matrix called `Predicted matrix` was created using `csc_matrix` method, where Predicted column was also passed along with movie_id, user_id, and ratings.

Computed a `Cost Function` which takes `root-mean-square` values of both the matrices (actual and predicted).



# Learning:

The `Gradient Descent` algorithm was developed to optimize the cost function when passing through many iterations (approx ~ 1000). 

    Gradient Descent is used because the loss function computed has to be minimized in order to make sure the prediction comes close to the actual values. This is an iterative process and will be repeated till the loss function reaches an optimal value.
    
Calculated the loss for different `LearningRates` and different `Iterations` and compared the results. 



# Observations:

For `Iteration:1000` and `learning_rate:1`, the model yielded the best result. 
